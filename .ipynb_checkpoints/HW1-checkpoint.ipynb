{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZSgajd_s1Sos"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h5fkBXnd3EE9"
   },
   "outputs": [],
   "source": [
    "# Define hyper parameters\n",
    "lr = 0.01\n",
    "batch_size = 128\n",
    "epochs = 500\n",
    "\n",
    "input_size, layer_size, output_size = 2, 2, 1\n",
    "\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8TIIVYvhCJO4"
   },
   "outputs": [],
   "source": [
    "# Training step that occurs once every epoch\n",
    "def train_step(input, output):\n",
    "  # Gradient tape keeps track of the gradients of your variables, optimizer applies changes to weights based on said gradients\n",
    "  with tf.GradientTape() as tape:\n",
    "    model_output = model(input)\n",
    "    loss = loss_function(output, model_output)\n",
    "\n",
    "  gradients = tape.gradient(loss, trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "k5kYX_0-Ytbt"
   },
   "outputs": [],
   "source": [
    "# Function to generate input and desired output, currently updating to work with different batch sizes, causes errors atm.\n",
    "def generate_data(options):\n",
    "  dataset = []\n",
    "  truth = []\n",
    "  for _ in range(batch_size * epochs):\n",
    "    np.random.shuffle(options)\n",
    "    for x in options:\n",
    "      dataset.append(x)\n",
    "      if sum(x) == 1:\n",
    "        truth.append(1)\n",
    "      else:\n",
    "        truth.append(0)\n",
    "  return np.array(dataset), np.array(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0o2N8636dui",
    "outputId": "c43b4f96-8446-4ca3-c933-59b2251b2087"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 49/500 [00:00<00:04, 111.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Loss: 0.7175527811050415\n",
      "Epoch: 40 Loss: 0.7146962881088257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 83/500 [00:00<00:02, 140.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 Loss: 0.712153434753418\n",
      "Epoch: 80 Loss: 0.7098997235298157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 119/500 [00:01<00:02, 155.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 Loss: 0.7079047560691833\n",
      "Epoch: 120 Loss: 0.7061364650726318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 172/500 [00:01<00:02, 163.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140 Loss: 0.704564094543457\n",
      "Epoch: 160 Loss: 0.7031590938568115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 205/500 [00:01<00:01, 153.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180 Loss: 0.7018965482711792\n",
      "Epoch: 200 Loss: 0.7007545232772827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 241/500 [00:01<00:01, 165.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220 Loss: 0.6997146606445312\n",
      "Epoch: 240 Loss: 0.6987611651420593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 295/500 [00:02<00:01, 169.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 260 Loss: 0.6978808641433716\n",
      "Epoch: 280 Loss: 0.6970627903938293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 333/500 [00:02<00:00, 173.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300 Loss: 0.6962977051734924\n",
      "Epoch: 320 Loss: 0.6955777406692505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 371/500 [00:02<00:00, 178.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340 Loss: 0.6948964595794678\n",
      "Epoch: 360 Loss: 0.6942484974861145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 407/500 [00:02<00:00, 173.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380 Loss: 0.6936292052268982\n",
      "Epoch: 400 Loss: 0.6930345296859741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 444/500 [00:02<00:00, 178.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 420 Loss: 0.692461371421814\n",
      "Epoch: 440 Loss: 0.6919068098068237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 482/500 [00:03<00:00, 178.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 460 Loss: 0.6913683414459229\n",
      "Epoch: 480 Loss: 0.690843939781189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 500/500 [00:03<00:00, 153.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500 Loss: 0.6903318762779236\n",
      "tf.Tensor(\n",
      "[[0.2914319 ]\n",
      " [0.07024306]\n",
      " [0.13296473]\n",
      " [0.45500362]], shape=(4, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input = [[1,0],[0,1],[1,1],[0,0]]\n",
    "\n",
    "# Define weights and biases\n",
    "w1 = tf.Variable(tf.random.normal([input_size, layer_size]), name='W1')\n",
    "wout = tf.Variable(tf.random.normal([layer_size,output_size]), name='Wout')\n",
    "\n",
    "b1 = tf.Variable(tf.zeros(shape=[layer_size]),name='b1')\n",
    "bout = tf.Variable(tf.zeros(shape=[output_size]),name='bout')\n",
    "trainable_variables = [w1, wout, b1, bout]\n",
    "\n",
    "\n",
    "fullset, truth = generate_data(input)\n",
    "\n",
    "# Define the structure of the model itself\n",
    "def model(x):\n",
    "  layer_output = tf.add(tf.matmul(x,w1),b1)\n",
    "  final_output = tf.add(tf.matmul(layer_output,wout),bout)\n",
    "  activation_output = tf.keras.activations.sigmoid(final_output)\n",
    "  return activation_output\n",
    "\n",
    "# Train and print results TODO: loss graph to help with optimization\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  batch_index = batch_size*epoch\n",
    "  batch, real_output = fullset[batch_index:(batch_index+batch_size)], truth[batch_index:(batch_index+batch_size)]\n",
    "  loss = train_step(tf.constant(batch, dtype=tf.float32), tf.constant(real_output, dtype=tf.float32))\n",
    "\n",
    "  if ((epoch + 1) % 20) == 0:\n",
    "    print('Epoch: {} Loss: {}'.format((epoch+1), loss.numpy()))\n",
    "  \n",
    "print(model(tf.constant(input, dtype=tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tnW2Yas47E4C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
