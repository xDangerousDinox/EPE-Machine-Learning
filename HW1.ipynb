{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZSgajd_s1Sos"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h5fkBXnd3EE9"
   },
   "outputs": [],
   "source": [
    "# Define hyper parameters\n",
    "lr = 0.01\n",
    "batch_size = 128\n",
    "epochs = 500\n",
    "\n",
    "input_size, layer_size, output_size = 2, 2, 1\n",
    "\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8TIIVYvhCJO4"
   },
   "outputs": [],
   "source": [
    "# Training step that occurs once every epoch\n",
    "def train_step(input, output):\n",
    "  # Gradient tape keeps track of the gradients of your variables, optimizer applies changes to weights based on said gradients\n",
    "  with tf.GradientTape() as tape:\n",
    "    model_output = model(input)\n",
    "    loss = loss_function(output, model_output)\n",
    "\n",
    "  gradients = tape.gradient(loss, trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "k5kYX_0-Ytbt"
   },
   "outputs": [],
   "source": [
    "# Function to generate input and desired output, currently updating to work with different batch sizes, causes errors atm.\n",
    "def generate_data(options):\n",
    "  dataset = []\n",
    "  truth = []\n",
    "  for _ in range(batch_size * epochs):\n",
    "    np.random.shuffle(options)\n",
    "    for x in options:\n",
    "      dataset.append(x)\n",
    "      if sum(x) == 1:\n",
    "        truth.append(1)\n",
    "      else:\n",
    "        truth.append(0)\n",
    "  return np.array(dataset), np.array(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0o2N8636dui",
    "outputId": "c43b4f96-8446-4ca3-c933-59b2251b2087"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▌                                                                           | 34/500 [00:00<00:05, 81.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Loss: 0.7205319404602051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▉                                                                        | 55/500 [00:00<00:04, 91.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 Loss: 0.7203115820884705\n",
      "Epoch: 60 Loss: 0.7200929522514343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▋                                                                 | 97/500 [00:01<00:04, 97.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 Loss: 0.719875693321228\n",
      "Epoch: 100 Loss: 0.7196601629257202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▊                                                          | 136/500 [00:01<00:04, 85.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120 Loss: 0.7194459438323975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████                                                       | 157/500 [00:01<00:03, 92.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140 Loss: 0.7192332744598389\n",
      "Epoch: 160 Loss: 0.7190223336219788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████                                                  | 188/500 [00:02<00:03, 96.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180 Loss: 0.7188129425048828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████▎                                              | 208/500 [00:02<00:03, 91.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200 Loss: 0.7186049818992615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▏                                         | 239/500 [00:02<00:02, 91.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220 Loss: 0.7183986902236938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                        | 250/500 [00:02<00:02, 94.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240 Loss: 0.7181939482688904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████▏                                    | 270/500 [00:03<00:02, 90.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 260 Loss: 0.7179906964302063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████▏                                 | 289/500 [00:03<00:02, 72.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280 Loss: 0.7177890539169312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████▊                              | 311/500 [00:03<00:02, 64.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300 Loss: 0.7175889015197754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████▍                          | 334/500 [00:04<00:02, 69.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320 Loss: 0.7173904180526733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▏                       | 351/500 [00:04<00:01, 75.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340 Loss: 0.7171933054924011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████▋                     | 367/500 [00:04<00:01, 70.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360 Loss: 0.7169979214668274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████▎                | 396/500 [00:04<00:01, 86.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380 Loss: 0.7168040871620178\n",
      "Epoch: 400 Loss: 0.7166117429733276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████▉          | 437/500 [00:05<00:00, 94.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 420 Loss: 0.7164210081100464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████▌        | 447/500 [00:05<00:00, 85.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 440 Loss: 0.7162317037582397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████████▏   | 476/500 [00:05<00:00, 84.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 460 Loss: 0.7160440683364868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:05<00:00, 83.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 480 Loss: 0.715857982635498\n",
      "Epoch: 500 Loss: 0.7156733274459839\n",
      "tf.Tensor(\n",
      "[[0.45879886]\n",
      " [0.39055267]\n",
      " [0.41271138]\n",
      " [0.43600276]], shape=(4, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input = [[1,0],[0,1],[1,1],[0,0]]\n",
    "\n",
    "# Define weights and biases\n",
    "w1 = tf.Variable(tf.random.normal([input_size, layer_size]), name='W1')\n",
    "wout = tf.Variable(tf.random.normal([layer_size,output_size]), name='Wout')\n",
    "\n",
    "b1 = tf.Variable(tf.zeros(shape=[layer_size]),name='b1')\n",
    "bout = tf.Variable(tf.zeros(shape=[output_size]),name='bout')\n",
    "trainable_variables = [w1, wout, b1, bout]\n",
    "\n",
    "\n",
    "fullset, truth = generate_data(input)\n",
    "\n",
    "# Define the structure of the model itself\n",
    "def model(x):\n",
    "  layer_output = tf.add(tf.matmul(x,w1),b1)\n",
    "  final_output = tf.add(tf.matmul(layer_output,wout),bout)\n",
    "  activation_output = tf.keras.activations.sigmoid(final_output)\n",
    "  return activation_output\n",
    "\n",
    "# Train and print results TODO: loss graph to help with optimization\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  batch_index = batch_size*epoch\n",
    "  batch, real_output = fullset[batch_index:(batch_index+batch_size)], truth[batch_index:(batch_index+batch_size)]\n",
    "  loss = train_step(tf.constant(batch, dtype=tf.float32), tf.constant(real_output, dtype=tf.float32))\n",
    "\n",
    "  if ((epoch + 1) % 20) == 0:\n",
    "    print('Epoch: {} Loss: {}'.format((epoch+1), loss.numpy()))\n",
    "  \n",
    "print(model(tf.constant(input, dtype=tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnW2Yas47E4C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
